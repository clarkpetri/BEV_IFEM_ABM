{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error \n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go\n",
    "from datetime import timedelta\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "# Data prep\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Step back one folder to reach the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# For plots later\n",
    "# Define a list of shades of gray\n",
    "shades_of_gray = ['#AAAAAA', '#999999', '#888888', '#777777', '#666666', '#555555', '#444444', '#333333', '#222222', '#111111']\n",
    "\n",
    "# Initialize counter for shades of gray\n",
    "shade_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(df1, df2):\n",
    "    correlation = np.corrcoef(df1, df2)[0, 1]\n",
    "    mean_absolute_error = np.mean(np.abs(df1 - df2))\n",
    "    root_mean_square_error = np.sqrt(np.mean((df1 - df2)**2))\n",
    "    return correlation, mean_absolute_error, root_mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(df):\n",
    "    '''Function to find best RunId from a sweep'''\n",
    "    \n",
    "    score = 200\n",
    "    best_run = None\n",
    "    \n",
    "    rmses = []\n",
    "    \n",
    "    unique_entries = df['RunId'].unique()\n",
    "    \n",
    "    for RunId in unique_entries:\n",
    "        df2 = df[df['RunId'] == RunId]\n",
    "        filtered_df = df2[df2['Step'] >= 64].drop_duplicates(subset=['Step'])\n",
    "        \n",
    "        corr, mae, rmse = calculate_similarity(filtered_df['normalized_bevs'], filtered_df['normalized_bev_target'])\n",
    "        \n",
    "        rmses.append(rmse)\n",
    "        \n",
    "        if rmse < score:\n",
    "            \n",
    "            score = rmse\n",
    "            best_run = RunId\n",
    "            \n",
    "    return best_run, score, rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interrun_corr(df):\n",
    "    '''Function to correlations between runs in a sweep'''\n",
    "    \n",
    "    corrs = []\n",
    "    \n",
    "    unique_entries = df['RunId'].unique()\n",
    "    \n",
    "    # Generate unique combinations of RunIds\n",
    "    run_combinations = itertools.combinations(unique_entries, 2)\n",
    "    \n",
    "    for RunId1, RunId2 in run_combinations:\n",
    "        df1 = df[df['RunId'] == RunId1]\n",
    "        df2 = df[df['RunId'] == RunId2]\n",
    "        \n",
    "        filtered_df1 = df1[df1['Step'] >= 64].drop_duplicates(subset=['Step'])\n",
    "        filtered_df2 = df2[df2['Step'] >= 64].drop_duplicates(subset=['Step'])\n",
    "        \n",
    "        corr, mae, rmse = calculate_similarity(filtered_df1['normalized_bevs'], filtered_df2['normalized_bevs'])\n",
    "        \n",
    "        corrs.append(corr)\n",
    "            \n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name, size = '01 - Baseline all 1.0 params 90k 8it', 62278 # Average: 24.3921, Corr: 0.9999\n",
    "#name, size = '01 - Baseline all 1.0 params 150k 8it', 100946 # Average: 24.6198,  Corr: 0.9999\n",
    "#name, size = '01 - Baseline all 1.0 params full pop 8it', 506959 # Average: 24.5670 Corr: 0.9999\n",
    "\n",
    "#name, size = '02 - Baseline 1.0 params 3.5 thresh 90k 8it', 62278 # Average: 0.1602, Corr: 0.9999, Fig 5.13\n",
    "\n",
    "#name, size = '03 - Optimized Params 90k 8it', 62278 # Average: 0.1148, Corr: 0.9985, Fig 5.14\n",
    "#name, size = '03 - Optimized Params 90k 100it', 62278 # Average: 0.1081\n",
    "#name, size = '03 - Optimized Params NO NEWS 90k 8it', 62278 # Average: 0.1602, Corr: 0.9987\n",
    "\n",
    "name, size = '03 - Optimized Params 83x83 full pop 8it', 506959 # Average: 0.0915\n",
    "\n",
    "#name, size = 'Rogers Best Params 90k 8it', 62278 # Average: 0.1191, Corr: 0.9987\n",
    "\n",
    "#name, size = 'rogers best current params 90k 40it', 62278\n",
    "\n",
    "#name, size = 'test', 62278\n",
    "\n",
    "file_path = os.path.join(parent_directory, 'Output data', name, 'FairfaxABM_Data.csv')\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_bev_target'] = (df['bev_target'] / size) * 100\n",
    "df['normalized_bevs'] = (df['bevs'] / size) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = find_best(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best run: {result[0]}, Best run RMSE: {result[1]:.4f}, Average RMSE: {(sum(result[2])/len(result[2])):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_run_corrs = find_interrun_corr(df)\n",
    "print('Average corr between runs:',(sum(inter_run_corrs)/len(inter_run_corrs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>All runs and average</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Filter the dataframe\n",
    "filtered_df = df[df['Step'] >= 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert ticks to datetime\n",
    "def tick_to_date(tick, start_month=5, start_year=2014):\n",
    "    start_date = pd.Timestamp(year=start_year, month=start_month, day=1)\n",
    "    return start_date + pd.DateOffset(months=tick-64)\n",
    "\n",
    "# Apply the conversion function to the 'Step' column\n",
    "filtered_df['Date'] = filtered_df['Step'].apply(tick_to_date)\n",
    "\n",
    "# 2) Plot 'bev_target'\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=filtered_df['Date'], y=filtered_df['normalized_bev_target'], mode='markers', name='Actual', marker=dict(size=5)))\n",
    "\n",
    "# 3) Plot 'bevs' for each run\n",
    "for run_id, group in filtered_df.groupby('RunId'):\n",
    "    shade = shades_of_gray[shade_index % len(shades_of_gray)]\n",
    "    fig.add_trace(go.Scatter(x=group['Date'], y=group['normalized_bevs'], mode='lines', name=f'Run {run_id}', line=dict(color=shade), opacity=0.4, showlegend=False))\n",
    "    shade_index+=1\n",
    "\n",
    "# 4) Plot the average of 'bevs' for all runs\n",
    "average_bevs = filtered_df.groupby('Step')['normalized_bevs'].mean()\n",
    "average_dates = pd.Series(average_bevs.index).apply(tick_to_date)\n",
    "fig.add_trace(go.Scatter(x=average_dates, y=average_bevs.values, mode='lines', name='Simulated', line=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title=name, xaxis_title='Date', yaxis_title='Percentage of BEVs')\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    y=0.85,\n",
    "    xanchor=\"right\",\n",
    "    x=0.135\n",
    "))\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = filtered_df[filtered_df['RunId'] == result[0]]\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inter-run correlation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = '03 - Optimized Params 90k 8it'\n",
    "fp1 = os.path.join(parent_directory, 'Output data', r1, 'FairfaxABM_Data.csv')\n",
    "df1 = pd.read_csv(fp1)\n",
    "df1 = df1.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "r2 = '03 - Optimized Params 83x83 full pop 8it'\n",
    "fp2 = os.path.join(parent_directory, 'Output data', r2, 'FairfaxABM_Data.csv')\n",
    "df2 = pd.read_csv(fp2)\n",
    "df2 = df2.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, mae, rmse = calculate_similarity(df1['bevs'], df2['bevs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
